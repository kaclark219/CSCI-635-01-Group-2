{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9535eb1",
   "metadata": {},
   "source": [
    "**Imports & Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b81d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 14:37:59.807635: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4fdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path(\"../../data/processed_balanced/train\")\n",
    "IMG_DIR = Path(\"../../data/processed\")\n",
    "VAL_DIR = IMG_DIR / \"validate\"\n",
    "TEST_DIR = IMG_DIR / \"test\"\n",
    "EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "RESULTS_DIR = Path(\"./results\")\n",
    "RESULTS_PATH = RESULTS_DIR / \"cnn_results.csv\"\n",
    "EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "\n",
    "# target styles for classification\n",
    "TARGET_STYLES = [\n",
    "    \"Abstract_Expressionism\",\n",
    "    \"Baroque\",\n",
    "    \"Cubism\",\n",
    "    \"Impressionism\",\n",
    "    \"Pop_Art\"\n",
    "]\n",
    "\n",
    "RANDOM_SEED = 635"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e05874",
   "metadata": {},
   "source": [
    "**Load Data & Normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57f62fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762803488.021838   12446 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1762803488.026643   12446 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 2s/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step\n",
      "Shapes: (15000, 2048) (4760, 2048) (4761, 2048)\n"
     ]
    }
   ],
   "source": [
    "# config for data loading and feature extraction\n",
    "BATCH = 64\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "EXPECT_SIZE = (256, 256)\n",
    "STRICT_SIZE = True\n",
    "\n",
    "# map from class name to label index\n",
    "CLASS_TO_IDX = {c: i for i, c in enumerate(TARGET_STYLES)}\n",
    "def list_paths_labels(root: Path):\n",
    "    paths, labels = [], []\n",
    "    for class_name in TARGET_STYLES:\n",
    "        class_dir = root / class_name\n",
    "        if not class_dir.exists():\n",
    "            continue\n",
    "        for path in sorted(class_dir.glob(f\"*\")):\n",
    "            if path.suffix.lower() in EXTS and path.is_file():\n",
    "                paths.append(str(path))\n",
    "                labels.append(CLASS_TO_IDX[class_name])\n",
    "    return np.array(paths, dtype=np.str_), np.array(labels, dtype=np.int32)\n",
    "\n",
    "def decode_keep_size(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    if STRICT_SIZE:\n",
    "        shape = tf.shape(img)\n",
    "        assert_op = tf.debugging.assert_equal(\n",
    "            shape[:2], EXPECT_SIZE,\n",
    "            message=\"Non-224 image found\"\n",
    "        )\n",
    "        with tf.control_dependencies([assert_op]):\n",
    "            img = tf.identity(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = resnet50.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def build_dataset(paths, labels=None, shuffle=False):\n",
    "    x = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    x = x.map(decode_keep_size, num_parallel_calls=AUTO)\n",
    "    if labels is not None:\n",
    "        y = tf.data.Dataset.from_tensor_slices(labels)\n",
    "        ds = tf.data.Dataset.zip((x, y))\n",
    "    else:\n",
    "        ds = x\n",
    "    if shuffle and len(paths) > 1:\n",
    "        ds = ds.shuffle(buffer_size=min(10000, len(paths)), seed=42, reshuffle_each_iteration=False)\n",
    "    ds = ds.batch(BATCH).prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "# load ResNet50 model\n",
    "backbone = resnet50.ResNet50(include_top=False, weights=\"imagenet\", pooling=\"avg\")\n",
    "train_paths, y_train = list_paths_labels(TRAIN_DIR)\n",
    "val_paths, y_val = list_paths_labels(VAL_DIR)\n",
    "test_paths, y_test = list_paths_labels(TEST_DIR)\n",
    "\n",
    "# build datasets\n",
    "train_ds = build_dataset(train_paths, y_train, shuffle=True)\n",
    "val_ds = build_dataset(val_paths, y_val)\n",
    "test_ds = build_dataset(test_paths, y_test)\n",
    "\n",
    "# extract features\n",
    "X_train = backbone.predict(train_ds)\n",
    "X_val = backbone.predict(val_ds)\n",
    "X_test = backbone.predict(test_ds)\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b930cea",
   "metadata": {},
   "source": [
    "**Regularized CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335dc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "450f585e",
   "metadata": {},
   "source": [
    "**Export Results & Visuals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9a8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
